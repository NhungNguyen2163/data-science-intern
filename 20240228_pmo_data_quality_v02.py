# -*- coding: utf-8 -*-
"""20240228 - PMO - Data Quality - v02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zalstm5q3QyvtDzNG6z85JS5U7JqG_B3
"""

pip install pyspark

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, min, max
from collections import OrderedDict
import pandas as pd
from pyspark.sql.functions import expr
from pyspark.sql import Window
from pyspark.sql.functions import lag, when, isnull
from pyspark.sql.functions import to_date


# Create a Spark session
spark = SparkSession.builder.appName("example").getOrCreate()

df_sample = pd.read_csv('/content/test.csv')

# df_sample = df_sample.iloc[:80000,:]

# df_sample.to_csv('/content/test.csv')

from pyspark.sql.functions import date_format
# Convert the string column to a timestamp column
df = df.withColumn('dump_datetime', to_timestamp(df.dump_datetime, 'dd/MM/yy HH:mm:ss'))
# Extract the date portion from the timestamp
df = df.withColumn ('date_only', date_format(df.dump_datetime, 'yyyy-MM-dd'))
df.show(5)

"""```
# This is formatted as code
```

# **1. Tính đầy đủ**

**Quy tắc kiểm tra, đánh giá chất lượng dữ liệu**

- Kiểm tra tính đầy đủ của bảng dữ liệu theo khoảng thời gian yêu cầu, tuần suất yêu cầu
- Kiểm tra tính đầy đủ của các trường dữ liệu theo yêu cầu của bảng
- Kiểm tra tỷ lệ nhận giá trị trống (null/blank) và/hoặc nhận giá trị bằng 0
- Kiểm tra tất cả các khóa ngoại khác null phải tìm được khóa chính phù hợp, ràng buộc này được thực hiện giữa 2 bảng dữ liệu

## **1.1 Khoảng thời gian dữ liệu nhận được có đầy đủ theo yêu cầu hay không?**

*   Mục danh sách
*   Mục danh sách
"""

url_subscriber = "/content/train.csv"

df = df_sample
df_spark = spark.createDataFrame(df)

print(f' Ngày đầu tiên trong bảng dữ liệu là : {df.agg(min(col(date_column))).collect()[0][0]}')
print(f' Ngày cuối cùng trong bảng dữ liệu là : {df.agg(max(col(date_column))).collect()[0][0]}')

print(f'So luong dong trong bang nay la {df.count()}') # Dùng để thu thập thông tin số dòng, không liên quan phần anyf

"""## **1.2 Số lượng thời điểm quan sát của dữ liệu nhận được có đầy đủ hay không?**"""

def date_enough(df, date_col, rep_date):
    """
    Chuc nang: dung de kiem tra ngay con thieu trong dataframe (Vi du du lieu hien tai khong luu theo ngay ma luu theo thang
    - df: du lieu de check
    - date_col: cot ngay lam chuan de check
    - rep_date: cot thay the (trong TH du lieu la dang string -> datetime)

    Ket qua:
    - Tra ve cac ngay con thieu trong cot ngay cua du lieu

    """
    df = df.withColumn(rep_date, col(date_col).cast("timestamp"))

    # Convert the result to a list

    return df.select(rep_date).distinct().count()

len(date_enough(df, "dump_datetime", 'date_only')[0])

"""## **1.3 Thời gian quan sát của dữ liệu nhận được đúng yêu cầu không**



"""

# Check truc tiep ambari, ngay gan nhat hay khong

"""## **1.4 Bảng dữ liệu có đủ trường theo yêu cầu**

- Các trường bảng là gì? Đúng với yêu cầu hay không
  + Số trường
  + Loại dữ liệu tương ứng
  + Các cột khác biệt là gì
  + Phương án tiếp cận
"""

df.show(2)

"""## **1.5 Các trường dữ liệu có tỷ lệ null ở mức chấp nhận  không?**




"""

for column in df.columns:
        null_count = df.filter(col(column).isNull()).count()
        print(f'Cot {column} co so dong null la {null_count}')



check_null_ratio(df, threshold=0.05)

"""## **1.6 Các trường dạng number có tỷ giá trị bằng 0 ở mức chấp nhận không?**"""

for column in df.columns:
        null_count = df.where(col(column) == '0').count() # Dieu kien = 0

        print(f'Cot {column} co so dong bang 0 la {null_count}')

check_zero_ratio(df, 0.05)

"""## **1.7 Các trường dạng text có tỷ lệ giá trị bằng " ‘’ ở mức chấp nhận không?**"""

for column in df.columns:
        null_count = df.where(col(column) == "").count() + df.where(col(column)==" ").count()
        print(f'Cot {column} co so dong bang "" la {null_count}')
    #return null_ratios

check_string_empty_ratio(df, 0.05)

"""## **1.8 Nếu trường dữ liệu của bảng là khóa ngoại của bảng dữ liệu khác, kiểm tra xem có mapping được 100% toàn bộ các giá trị khóa ngoại không?**"""

def check_mapping(df_f1, df_f2, col1, col2):
  #Collect unique
  """
  Chuc nang: dung de kiem tra xem hai khoa ngoai co mapping duoc voi nhau hay khong
  - Cach lam: so luong unique value cua tung df_1 co bang nhau hay lon hon khong
  - Kiem tra check_1, check_2 bang cach tru tap hop unique

  Ket qua:
  - check_1 co gia tri -> bang df_2 khong mapping duoc voi bang df_1 va nguoc lai
  - Neu check_1, check_2 null -> Dieu kien 1.8 ok
  """

  set_f1 = set(df_f1.select(col1).distinct().collect())
  set_f2 = set(df_f2.select(col1).distinct().collect())

  #Check the remain
  check_1 = set_f1 - set_f2
  check_2 = set_f2 - set_f1
  if check_1:
    print(f'Bang {df_f2} khong mapping duoc 100% bang {df_f1}')
    return check_f1
  if check_2:
    print(f'Bang {df_f1} khong mapping duoc 100% bang {df_f2}')
    return check_f2
  else:
    'Dieu kien 1.8 ok'

"""## **1.9 Nếu trường dữ liệu của bảng là khóa ngoại, kiểm tra xem có mapping được 100% toàn bộ các giá trị với bảng dữ liệu chứa khóa chính không?**"""

def check_key(df_pri, df_for, col1, col2):
  """
  Tuong tu 1.8 tuy nhien ap dung cho bang fact&dim
  """

  set_primary = set(df_pri.select(col1).distinct().collect())
  set_foreign = set(df_pri.select(col2).distinct().collect())
  check_1 = set_foreign - set_primary
  if len(set_foreign) > len(set_primary) or len(check_1) >0:
    print('Loi for key co nhieu gia tri unique hon gia tri pri key')
    return check_1
  else:
    'Dieu kien 1.9 ok'

"""# **2 Tính độc nhất**

-	Kiểm tra trùng lặp (duplicate) dữ liệu theo khóa chính (primary key) của bảng.

## **2.1 Bảng dữ liệu nhận được có bị trùng khóa chính không?**
"""

def check_duplicates(df, primary_key_columns):
    """
    Check for duplicate values in the primary key columns of a PySpark DataFrame.

    Parameters:
        df (pyspark.sql.DataFrame): The DataFrame to check for duplicates.
        primary_key_columns (list): List of column names that constitute the primary key.

    Returns:
        bool: True if there are duplicates, False otherwise.
    """
    # Group by the primary key columns and count the occurrences
    grouped_df = df.groupBy(primary_key_columns).count()

    # Filter for rows where the count is greater than 1 (indicating duplicates)
    duplicates = grouped_df.filter(col("count") > 1)

    # If duplicates are found, return True; otherwise, return False
    if duplicates.count() > 0:
        print("Primary key is duplicated")
    else:
        print("No Duplicated Primary Key")
    return duplicates

df.show()

"""# **3.Kiểm tra thời điểm nhận được dữ liệu so với thời điểm quan sát (chỉ áp dụng với các dữ liệu được quy hoạch định kỳ).**"""



"""# **4.Tính hợp lệ**

-	Kiểm tra các giá trị của trường dữ liệu dạng tham số có nằm trong bảng tham số;
-	Kiểm tra phân phối dữ liệu (số lượng bản ghi, giá trị tối thiểu - min, giá trị tối đa - max, bách phân vị thứ 5 – percentile 5%, giá trị trung vị - median, bách phân vị thứ 95 – percentile 95%, giá trị ngoại lai - outlier);
-	Kiểm tra định dạng, kiểu giá trị;
-	Kiểm tra giá trị theo các ràng buộc giới hạn;
-	Kiểm tra khả năng chuyển đổi về kiểu dữ liệu phù hợp.

## **4.1 •	Trường có chứa các ký tự đặc biệt hay không?**
Lưu ý:
-	Nguyên tắc này chỉ áp dụng với các trường dạng text.
-	Ký tự đặc biệt là các ký tự không có trên bàn phím máy tính, thường do các hệ thống tự sinh.
"""

for column in df.columns:
		has_special_characters = df.filter(df[col].contains('[\!\@\#\$\%\^\&\*\-\_\?\:\;]')).count()
		print(f'Cot {column} co {has_special_characters} dong co gia tri dac biet')

"""## **4.2 Các giá trị của trường có nằm trong bảng tham số hay không?**

## **4.3 Số lượng bản ghi của trường có biến động trong mức chấp nhận không?**

## **4.4 Số lượng bản ghi không null của trường có biến động trong mức chấp nhận không?**
"""

# check tay
# code
# uu tien check tay -> Cap nhat bo sung

	for column in df.columns:
		null_count = df.where(col(column) == "0").count()
		print(f"Cot {column} co ty le 0 la {null_count}")

"""## **4.5 Giá trị nhỏ nhất của trường có biến động trong mức chấp nhận không?**"""

# Chuyen du lieu sang dang float
# Tinh toan gia tri nho nhat cho tung cot
for num_col in ['main_balance']:
  df_stg = df.withColumn(num_col, df[num_col].cast('float'))
  df_stg.agg({num_col: 'min'}).show()

"""## **4.6 Giá trị lớn nhất của trường có biến động trong mức chấp nhận không?**"""

# Chuyen du lieu sang dang float
# Tinh toan gia tri lon nhat cho tung cot
for num_col in ['main_balance']:
  df_stg = df.withColumn(num_col, df[num_col].cast('float'))
  df_stg.agg({num_col: 'max'}).show()

"""## **4.7 Giá trị bách phân vị thứ 5 – percentile 5% của trường có biến động trong mức chấp nhận không?**"""

# Chuyen du lieu sang dang float
# Tinh toan gia tri percentile 5%
for num_col in ['main_balance']:
  df_stg = df.withColumn(num_col, df[num_col].cast('float'))
  value = df_stg.approxQuantile(num_col, [0.05], 0.1)
  print(f'Cot {num_col} co gia tri tai pv 5% la {value}')

"""## **4.8	Giá trị bách phân vị thứ 95 - percentile 95% của trường có biến động trong mức chấp nhận không?**"""

# Chuyen du lieu sang dang float
# Tinh toan gia tri percentile 95%
for num_col in ['main_balance']:
  df_stg = df.withColumn(num_col, df[num_col].cast('float'))
  value = df_stg.approxQuantile(num_col, [0.95], 0.1)
  print(f'Cot {num_col} co gia tri tai pv 5% la {value}')

"""## **4.9 •	Định dạng, kiểu dữ liệu của trường có đúng theo yêu cầu không?**"""

# Ở phần trên metadata có check rồi

"""## **4.10 Các giá trị của trường có nằm trong giới hạn không?**"""

# Bên kia cung cấp -> Đưa giá trị min max

"""## **4.11 Các giá trị của trường có khả năng chuyển đổi toàn bộ về kiểu dữ liệu khác phù hợp hay không?**"""

df.withColumn('dump_datetime', df['dump_datetime'].cast('date')).show()

"""# **5.Tính chính xác**

- Kiểm tra tính chính xác của trường thông qua các lô-gic trong cùng bảng dữ liệu;
- Kiểm tra tính chính xác của trường thông qua các lô-gic theo chuỗi thời gian;
- Kiểm tra tính chính xác của trường thông qua các lô-gic giữa các bảng dữ liệu;
- Kiểm tra chọn mẫu với hệ thống sinh dữ liệu gốc (hoặc với hồ sơ thực tế).
- Kiểm tra xu hướng kỳ vọng của dữ liệu.

## **5.1	Trường dữ liệu có đáp ứng các nguyên tắc kiểm tra chéo giữa các trường trong cùng bảng dữ liệu không?**
"""



"""# **5.2. Kiểm tra chi tiết 'main_balance' và 'last_topup_date'**

"""

df=df.withColumn('last_topup_date_x', to_date('last_topup_date', 'dd/MM/yyyy'))
df_test = df.filter(df['last_topup_date_x'].isNull())

df_test.show(10)

df_t2 = df_test.groupBy(['last_topup_date_x','main_balance']).count()
df_t2.filter(df_t2['main_balance']==0).show()

df_test.count()

df=df.withColumn('main_balance',col('main_balance').cast('float'))
df.approxQuantile('main_balance', [0.01,0.25,0.5,0.75,0.99],0.0)

print(f'Gia tri lon nhat {df.select(max('main_balance')).first()[0]}')
print(f'Gia tri nho nhat {df.select(min('main_balance')).first()[0]}')

df_am = df.filter(df['main_balance']<0)
df_am.count()

df_am.approxQuantile('main_balance', [0.01,0.25,0.5,0.75,0.99],0.0)